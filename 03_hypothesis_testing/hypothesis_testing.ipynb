{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01",
   "metadata": {},
   "source": [
    "# 03 â€” Hypothesis Testing\n",
    "**Author:** Ebenezer Adjartey\n\n",
    "Covers: one-sample & two-sample t-tests, paired t-test, ANOVA (one-way, two-way), chi-square tests, z-test for proportions, F-test, multiple comparisons (Bonferroni, Tukey)."
   ]
  },
  {
   "cell_type": "code",
   "id": "c02",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "np.random.seed(42)\n",
    "sns.set_theme(style='whitegrid')\n",
    "print('Libraries loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03",
   "metadata": {},
   "source": [
    "## 1. One-Sample t-Test"
   ]
  },
  {
   "cell_type": "code",
   "id": "c04",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# H0: mu = 70  vs  H1: mu != 70\n",
    "scores = np.random.normal(72, 12, 30)\n",
    "t_stat, p_val = stats.ttest_1samp(scores, popmean=70)\n",
    "ci = stats.t.interval(0.95, df=len(scores)-1,\n",
    "                       loc=scores.mean(), scale=stats.sem(scores))\n",
    "print(f'Sample mean = {scores.mean():.3f}')\n",
    "print(f't-statistic = {t_stat:.4f}')\n",
    "print(f'p-value     = {p_val:.4f}')\n",
    "print(f'95% CI      = ({ci[0]:.3f}, {ci[1]:.3f})')\n",
    "print('Verdict:', 'Reject H0' if p_val < 0.05 else 'Fail to reject H0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05",
   "metadata": {},
   "source": [
    "## 2. Two-Sample t-Test (Independent)"
   ]
  },
  {
   "cell_type": "code",
   "id": "c06",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# H0: mu1 = mu2  (equal variance)\n",
    "group_a = np.random.normal(75, 10, 40)\n",
    "group_b = np.random.normal(70, 12, 40)\n",
    "\n",
    "# Equal variance (Student's t)\n",
    "t_eq, p_eq = stats.ttest_ind(group_a, group_b, equal_var=True)\n",
    "print(f'Equal variance t-test: t={t_eq:.4f}, p={p_eq:.4f}')\n",
    "\n",
    "# Unequal variance (Welch's t)\n",
    "t_w, p_w = stats.ttest_ind(group_a, group_b, equal_var=False)\n",
    "print(f\"Welch's t-test:        t={t_w:.4f}, p={p_w:.4f}\")\n",
    "\n",
    "# Levene's test for equal variances\n",
    "lev_stat, lev_p = stats.levene(group_a, group_b)\n",
    "print(f\"Levene's test (equal var): W={lev_stat:.4f}, p={lev_p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07",
   "metadata": {},
   "source": [
    "## 3. Paired t-Test"
   ]
  },
  {
   "cell_type": "code",
   "id": "c08",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# H0: mean difference = 0  (before vs after treatment)\n",
    "before = np.random.normal(120, 15, 25)\n",
    "after  = before - np.random.normal(8, 5, 25)   # treatment reduces by ~8\n",
    "t_p, p_p = stats.ttest_rel(before, after)\n",
    "diff = before - after\n",
    "print(f'Mean difference (before - after) = {diff.mean():.3f}')\n",
    "print(f'Paired t-statistic = {t_p:.4f}')\n",
    "print(f'p-value            = {p_p:.4f}')\n",
    "print('Verdict:', 'Significant change' if p_p < 0.05 else 'No significant change')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09",
   "metadata": {},
   "source": [
    "## 4. One-Way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "id": "c10",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# H0: all group means equal\n",
    "g1 = np.random.normal(70, 10, 30)\n",
    "g2 = np.random.normal(75, 10, 30)\n",
    "g3 = np.random.normal(80, 10, 30)\n",
    "\n",
    "f_stat, p_anova = stats.f_oneway(g1, g2, g3)\n",
    "print(f'One-Way ANOVA: F={f_stat:.4f}, p={p_anova:.4f}')\n",
    "print('Verdict:', 'At least one mean differs' if p_anova < 0.05 else 'No significant difference')\n",
    "\n",
    "# Effect size (eta-squared)\n",
    "all_data = np.concatenate([g1, g2, g3])\n",
    "grand_mean = all_data.mean()\n",
    "ss_between = sum(len(g)*(g.mean()-grand_mean)**2 for g in [g1,g2,g3])\n",
    "ss_total   = ((all_data - grand_mean)**2).sum()\n",
    "eta_sq = ss_between / ss_total\n",
    "print(f'Eta-squared (effect size) = {eta_sq:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11",
   "metadata": {},
   "source": [
    "## 5. Two-Way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "id": "c12",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Two factors: teaching_method + gender\n",
    "n = 120\n",
    "df_anova = pd.DataFrame({\n",
    "    'score':   np.random.normal(70, 10, n),\n",
    "    'method':  np.tile(['A','B','C'], n//3),\n",
    "    'gender':  np.repeat(['M','F'], n//2)\n",
    "})\n",
    "# Add method effect\n",
    "df_anova.loc[df_anova['method']=='B', 'score'] += 5\n",
    "df_anova.loc[df_anova['method']=='C', 'score'] += 10\n",
    "\n",
    "model = ols('score ~ C(method) + C(gender) + C(method):C(gender)', data=df_anova).fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "print('Two-Way ANOVA Table:')\n",
    "print(anova_table.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13",
   "metadata": {},
   "source": [
    "## 6. Post-Hoc Multiple Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "id": "c14",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tukey HSD after one-way ANOVA\n",
    "all_scores = np.concatenate([g1, g2, g3])\n",
    "groups     = np.repeat(['G1','G2','G3'], 30)\n",
    "tukey = pairwise_tukeyhsd(all_scores, groups, alpha=0.05)\n",
    "print('Tukey HSD Results:')\n",
    "print(tukey)\n",
    "\n",
    "# Bonferroni correction\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "raw_p = [0.01, 0.04, 0.06, 0.12, 0.20]\n",
    "bon_reject, bon_p, _, _ = multipletests(raw_p, alpha=0.05, method='bonferroni')\n",
    "print('\\nBonferroni Correction:')\n",
    "for i, (rp, bp, rej) in enumerate(zip(raw_p, bon_p, bon_reject)):\n",
    "    print(f'  Test {i+1}: raw_p={rp:.2f} -> adj_p={bp:.3f} Reject={rej}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15",
   "metadata": {},
   "source": [
    "## 7. Chi-Square Tests"
   ]
  },
  {
   "cell_type": "code",
   "id": "c16",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 7a. Chi-square goodness-of-fit\n",
    "observed = np.array([45, 60, 55, 40])   # observed frequencies\n",
    "expected = np.array([50, 50, 50, 50])   # expected under H0 (uniform)\n",
    "chi2_gof, p_gof = stats.chisquare(observed, f_exp=expected)\n",
    "print(f'Goodness-of-fit: chi2={chi2_gof:.4f}, p={p_gof:.4f}')\n",
    "\n",
    "# 7b. Chi-square test of independence\n",
    "contingency = np.array([[30, 20], [15, 35]])\n",
    "chi2_ind, p_ind, dof, expected_ind = stats.chi2_contingency(contingency)\n",
    "print(f'\\nIndependence test: chi2={chi2_ind:.4f}, p={p_ind:.4f}, df={dof}')\n",
    "print('Expected frequencies:')\n",
    "print(expected_ind.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17",
   "metadata": {},
   "source": [
    "## 8. Z-Test for Proportions"
   ]
  },
  {
   "cell_type": "code",
   "id": "c18",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# H0: p = 0.50 (coin is fair)\n",
    "n_trials, n_success = 100, 60\n",
    "z_stat, p_z = proportions_ztest(n_success, n_trials, value=0.5)\n",
    "print(f'Z-test for proportion: z={z_stat:.4f}, p={p_z:.4f}')\n",
    "print('Verdict:', 'Reject H0' if p_z < 0.05 else 'Fail to reject H0')\n",
    "\n",
    "# 95% CI for proportion\n",
    "p_hat = n_success / n_trials\n",
    "se = np.sqrt(p_hat*(1-p_hat)/n_trials)\n",
    "ci_low  = p_hat - 1.96*se\n",
    "ci_high = p_hat + 1.96*se\n",
    "print(f'95% CI for proportion: ({ci_low:.4f}, {ci_high:.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19",
   "metadata": {},
   "source": [
    "## 9. F-Test for Equal Variances"
   ]
  },
  {
   "cell_type": "code",
   "id": "c20",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "sample1 = np.random.normal(50, 8, 30)\n",
    "sample2 = np.random.normal(50, 12, 30)\n",
    "\n",
    "# Levene's test (robust)\n",
    "lev_stat, lev_p = stats.levene(sample1, sample2)\n",
    "print(f\"Levene's test: W={lev_stat:.4f}, p={lev_p:.4f}\")\n",
    "\n",
    "# Bartlett's test (assumes normality)\n",
    "bart_stat, bart_p = stats.bartlett(sample1, sample2)\n",
    "print(f\"Bartlett's test: T={bart_stat:.4f}, p={bart_p:.4f}\")\n",
    "\n",
    "# Manual F-test\n",
    "F = sample1.var(ddof=1) / sample2.var(ddof=1)\n",
    "print(f'Manual F-ratio = {F:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "id": "c22",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Boxplot: three groups for ANOVA\n",
    "axes[0].boxplot([g1, g2, g3], labels=['G1','G2','G3'], patch_artist=True)\n",
    "axes[0].set_title(f'One-Way ANOVA\\nF={f_stat:.2f}, p={p_anova:.3f}')\n",
    "axes[0].set_ylabel('Score')\n",
    "\n",
    "# Paired data\n",
    "idx = np.arange(1, 11)\n",
    "axes[1].plot(idx, before[:10], 'bo-', label='Before')\n",
    "axes[1].plot(idx, after[:10],  'rs-', label='After')\n",
    "axes[1].set_title(f'Paired t-Test (n=25)\\nt={t_p:.2f}, p={p_p:.3f}')\n",
    "axes[1].legend(); axes[1].set_xlabel('Subject')\n",
    "\n",
    "# Chi-square distribution\n",
    "xc = np.linspace(0, 20, 300)\n",
    "axes[2].plot(xc, stats.chi2.pdf(xc, df=3), 'b-', lw=2)\n",
    "x_fill = np.linspace(chi2_gof, 20, 200)\n",
    "axes[2].fill_between(x_fill, stats.chi2.pdf(x_fill, df=3), alpha=.3, color='red', label='p-value region')\n",
    "axes[2].axvline(chi2_gof, color='red', linestyle='--', label=f'chi2={chi2_gof:.2f}')\n",
    "axes[2].set_title('Chi-Square GOF Test'); axes[2].legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "os.makedirs('03_hypothesis_testing', exist_ok=True)\n",
    "plt.savefig('03_hypothesis_testing/hypothesis_testing_plots.png', dpi=100, bbox_inches='tight')\n",
    "plt.show(); print('Saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23",
   "metadata": {},
   "source": [
    "## Key Takeaways\n\n",
    "- Always check assumptions (normality, equal variance) before choosing a test\n",
    "- Use Welch's t-test when variances are unequal\n",
    "- ANOVA tests overall mean equality; post-hoc tests identify which pairs differ\n",
    "- Bonferroni correction is conservative; Tukey HSD is better for pairwise comparisons\n",
    "- Chi-square tests are for categorical data\n"
   ]
  }
 ]
}